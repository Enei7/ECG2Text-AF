# ECG-LLMå¤šæ¨¡æ€æˆ¿é¢¤æ£€æµ‹ (Task 2)

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å°†Task 1è®­ç»ƒçš„CNNç‰¹å¾æå–å™¨ä¸Qwen-3-8Bå¤§è¯­è¨€æ¨¡å‹ç»“åˆ,æ„å»ºå¤šæ¨¡æ€ECGåˆ†ç±»ç³»ç»Ÿã€‚é€šè¿‡LoRAå¾®è°ƒ,ä½¿LLMèƒ½å¤Ÿç†è§£ECGä¿¡å·ç‰¹å¾å¹¶è¿›è¡Œæˆ¿é¢¤è¯Šæ–­ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æ•°æ®æµç¨‹](#æ•°æ®æµç¨‹)
- [æ¨¡å‹æ¶æ„](#æ¨¡å‹æ¶æ„)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [è¯„ä¼°ä¸æ¨ç†](#è¯„ä¼°ä¸æ¨ç†)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ç¯å¢ƒå‡†å¤‡

### 1. å‰ç½®æ¡ä»¶

- Task 1 å·²å®Œæˆè®­ç»ƒ,æ¨¡å‹æƒé‡ä½äº: `/home/zhenwei/workspace/ecg/task1/results/best.pth`
- Qwen-3-8B æ¨¡å‹å·²ä¸‹è½½åˆ°: `/home/zhenwei/models/Qwen3-8B`
- GPUå†…å­˜ â‰¥ 24GB (æ¨èä½¿ç”¨A100æˆ–V100)

### 2. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n llm python=3.10
conda activate llm

# å®‰è£…åŸºç¡€ä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…transformerså’ŒPEFT
pip install transformers>=4.36.0
pip install peft>=0.7.0
pip install accelerate>=0.25.0

# å®‰è£…å…¶ä»–ä¾èµ–
pip install numpy pandas scipy matplotlib scikit-learn tqdm
```

### 3. éªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import peft; print(f'PEFT: {peft.__version__}')"
```

---

## é¡¹ç›®ç»“æ„

```
ecg/task2/
â”œâ”€â”€ task2_dataset.py       # æŒ‡ä»¤æ•°æ®é›†ç±»
â”œâ”€â”€ task2_model.py         # å¤šæ¨¡æ€æ¨¡å‹å®šä¹‰
â”œâ”€â”€ task2_train.py         # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ task2_inference.py     # æ¨ç†è„šæœ¬(å¾…åˆ›å»º)
â”œâ”€â”€ task2_results/         # è®­ç»ƒç»“æœä¿å­˜ç›®å½•
â”‚   â”œâ”€â”€ checkpoint_epoch_*.pth
â”‚   â””â”€â”€ task2_metrics.txt
â””â”€â”€ README_task2.md        # æœ¬æ–‡ä»¶
```

---

## æ•°æ®æµç¨‹

### 1. æ•°æ®å¤„ç†ç®¡é“

```
ECGä¿¡å·(.mat) 
  â†“ [Task1 Dataset]
ECG Tensor [B, 1, 2400]
  â†“ [CNN Encoder - å†»ç»“]
ç‰¹å¾å‘é‡ [B, 1024]
  â†“ [Projector - å¯è®­ç»ƒ]
LLMåµŒå…¥ [B, 4096]
  â†“ [æ‹¼æ¥æ–‡æœ¬åµŒå…¥]
å¤šæ¨¡æ€è¾“å…¥ [B, Seq_len, 4096]
  â†“ [Qwen-3-8B + LoRA]
æ–‡æœ¬è¾“å‡º
```

### 2. æŒ‡ä»¤-ç­”æ¡ˆå¯¹æ„å»º

**æŒ‡ä»¤æ¨¡æ¿**:
```
è¯·ä½œä¸ºä¸€åå¿ƒè„ç—…ä¸“å®¶ï¼Œåˆ†æè¿™æ®µå¿ƒç”µå›¾ä¿¡å·ç‰¹å¾ã€‚<|ecg_feature|>è¯·åˆ¤æ–­è¯¥æ‚£è€…æ˜¯å¦æ‚£æœ‰æˆ¿é¢¤ï¼ˆAtrial Fibrillationï¼‰ï¼Ÿ
```

**ç­”æ¡ˆæ˜ å°„**:
- **Nç±»(0)**: "ç»è¿‡åˆ†æï¼Œè¯¥å¿ƒç”µå›¾æ˜¾ç¤ºä¸ºæ­£å¸¸çª¦æ€§å¿ƒå¾‹ï¼Œæ— æˆ¿é¢¤ã€‚"
- **Aç±»(1)**: "ç»è¿‡åˆ†æï¼Œè¯¥å¿ƒç”µå›¾æ˜¾ç¤ºç‰¹å¾ç¬¦åˆæˆ¿é¢¤ï¼ˆAFï¼‰è¡¨ç°,æœ‰æˆ¿é¢¤ã€‚"

### 3. æ•°æ®é›†åˆ’åˆ†

å¤ç”¨Task 1çš„åˆ’åˆ†ç­–ç•¥:
- **è®­ç»ƒé›†**: çº¦75% (4340ä¸ªæ ·æœ¬)
- **éªŒè¯é›†**: çº¦10% (579ä¸ªæ ·æœ¬)  
- **æµ‹è¯•é›†**: çº¦15% (869ä¸ªæ ·æœ¬)

**æ³¨æ„**: Task 2ä¸­ä¸ä½¿ç”¨æ•°æ®å¢å¼º,ä¿æŒè¾“å…¥ç¨³å®šæ€§

---

## æ¨¡å‹æ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ECGLLM æ¨¡å‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ ECG Signal  â”‚â”€â”€â”€â–¶â”‚ CNN Encoder  â”‚ (å†»ç»“)         â”‚
â”‚  â”‚ [B,1,2400]  â”‚    â”‚ (Task1æ¨¡å‹)  â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                              â”‚                        â”‚
â”‚                              â–¼                        â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                       â”‚  Features   â”‚                â”‚
â”‚                       â”‚  [B, 1024]  â”‚                â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                              â”‚                        â”‚
â”‚                              â–¼                        â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                       â”‚  Projector  â”‚ (å¯è®­ç»ƒ)       â”‚
â”‚                       â”‚  MLP+LN+DO  â”‚                â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                              â”‚                        â”‚
â”‚                              â–¼                        â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                       â”‚LLM Embeddingâ”‚                â”‚
â”‚                       â”‚  [B, 4096]  â”‚                â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                              â”‚                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚                                 â”‚           â”‚
â”‚         â–¼                                 â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Text Tokens  â”‚                  â”‚ECG Embeddingâ”‚   â”‚
â”‚  â”‚             â”‚                  â”‚             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                      â–¼                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚              â”‚   Qwen-3-8B  â”‚ (LoRAå¾®è°ƒ)             â”‚
â”‚              â”‚   + LoRA     â”‚                         â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                     â”‚                                 â”‚
â”‚                     â–¼                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚              â”‚ æ–‡æœ¬è¾“å‡º     â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®ç»„ä»¶

#### 1. CNN Encoder (æ¥è‡ªTask 1)
- **ç»“æ„**: MS-CNNåŒæµæ¶æ„
- **è¾“å…¥**: [B, 1, 2400]
- **è¾“å‡º**: [B, 1024] ç‰¹å¾å‘é‡
- **çŠ¶æ€**: **å†»ç»“** (ä¸æ›´æ–°æ¢¯åº¦)
- **ä½ç½®**: CPU (èŠ‚çœGPUæ˜¾å­˜)

#### 2. ECG Projector
- **ç»“æ„**: 
  ```
  Linear(1024 â†’ 4096)
  â†’ LayerNorm
  â†’ GELU
  â†’ Dropout(0.1)
  â†’ Linear(4096 â†’ 4096)
  ```
- **ä½œç”¨**: å°†ECGç‰¹å¾æ˜ å°„åˆ°LLMåµŒå…¥ç©ºé—´
- **çŠ¶æ€**: **å¯è®­ç»ƒ**

#### 3. Qwen-3-8B + LoRA
- **LoRAé…ç½®**:
  - rank (r): 16
  - alpha: 32
  - dropout: 0.05
  - target_modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
- **çŠ¶æ€**: ä»…LoRAå‚æ•°å¯è®­ç»ƒ (~8.4Må‚æ•°)

---

## è®­ç»ƒæµç¨‹

### 1. åŸºç¡€è®­ç»ƒ

```bash
cd /home/zhenwei/workspace/ecg/task2

# æ¿€æ´»ç¯å¢ƒ
conda activate llm

# å¼€å§‹è®­ç»ƒ (ç¡®ä¿k_size_stream2ä¸Task1ä¸€è‡´)
python task2_train.py --k_size_stream2 5
```

### 2. è®­ç»ƒå‚æ•°

**å›ºå®šå‚æ•°**:
- Batch Size: 4
- Gradient Accumulation: 4 æ­¥ (æœ‰æ•ˆbatch=16)
- Epochs: 3
- Learning Rate: 1e-4
- Warmup Steps: 100

**èµ„æºéœ€æ±‚**:
- GPUå†…å­˜: ~22-24GB
- è®­ç»ƒæ—¶é—´: çº¦2-3å°æ—¶/epoch (å•å¡A100)
- æ€»è®­ç»ƒæ—¶é—´: çº¦6-9å°æ—¶

### 3. è®­ç»ƒç›‘æ§

**è¾“å‡ºæŒ‡æ ‡**:
- æ¯æ­¥Loss
- Epochå¹³å‡Loss
- æ¢¯åº¦ç´¯ç§¯çŠ¶æ€

**æ£€æŸ¥ç‚¹ä¿å­˜**:
- `checkpoint_epoch_1.pth`
- `checkpoint_epoch_2.pth`
- `checkpoint_epoch_3.pth`

### 4. è®­ç»ƒæŠ€å·§

**æ˜¾å­˜ä¼˜åŒ–**:
```python
# 1. CNNæ”¾åœ¨CPU
model.ecg_encoder = model.ecg_encoder.cpu()

# 2. ä½¿ç”¨bfloat16
torch_dtype=torch.bfloat16

# 3. æ¢¯åº¦ç´¯ç§¯
GRAD_ACCUM_STEPS = 4

# 4. æ¢¯åº¦æ£€æŸ¥ç‚¹(å¯é€‰)
model.llm.gradient_checkpointing_enable()
```

**ç¨³å®šè®­ç»ƒ**:
- ä½¿ç”¨LayerNormç¨³å®šProjector
- é™ä½LoRA dropout (0.05)
- ä½¿ç”¨Warmupé¿å…åˆæœŸéœ‡è¡

---

## è¯„ä¼°ä¸æ¨ç†

### 1. è®­ç»ƒåè‡ªåŠ¨è¯„ä¼°

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°:

```
=== Task 2 æœ€ç»ˆè¯„ä¼° ===
Accuracy: 0.xxxx
F1-Score (AF): 0.xxxx
```

### 2. è¯„ä¼°æŒ‡æ ‡

- **Accuracy**: æ•´ä½“å‡†ç¡®ç‡
- **F1-Score**: Aç±»(æˆ¿é¢¤)çš„F1åˆ†æ•°
- **ç”Ÿæˆè´¨é‡**: é€šè¿‡å…³é”®è¯åŒ¹é…è¯„ä¼°

### 3. æ¨ç†ç¤ºä¾‹

```python
import torch
from transformers import AutoTokenizer
from task2_model import ECGLLM

# åŠ è½½æ¨¡å‹
model = ECGLLM(
    llm_path="/home/zhenwei/models/Qwen3-8B",
    cnn_checkpoint_path="/home/zhenwei/workspace/ecg/task1/results/best.pth",
    k_size_stream2=5
)

# åŠ è½½å¾®è°ƒæƒé‡
model.load_state_dict(torch.load("task2_results/checkpoint_epoch_3.pth"))
model.eval()

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained("/home/zhenwei/models/Qwen3-8B")

# æ¨ç†
ecg_signal = ...  # [1, 1, 2400]
output_text = model.generate(ecg_signal, tokenizer, max_new_tokens=50)
print(output_text)
```

---

## å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠ?

**A**: 
1. å‡å°batch_sizeåˆ°2æˆ–1
2. å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
4. ä½¿ç”¨æ›´å°çš„LoRA rank (r=8)

### Q2: è®­ç»ƒlossä¸ä¸‹é™?

**A**:
1. æ£€æŸ¥CNNæƒé‡æ˜¯å¦æ­£ç¡®åŠ è½½
2. ç¡®è®¤Projectorå‚æ•°å¯è®­ç»ƒ
3. é™ä½å­¦ä¹ ç‡åˆ°5e-5
4. å¢åŠ warmupæ­¥æ•°åˆ°200

### Q3: ç”Ÿæˆçš„æ–‡æœ¬ä¸ç¬¦åˆé¢„æœŸ?

**A**:
1. æ£€æŸ¥æŒ‡ä»¤æ¨¡æ¿æ ¼å¼
2. è°ƒæ•´ç­”æ¡ˆæ–‡æœ¬çš„æªè¾
3. å¢åŠ è®­ç»ƒè½®æ•°åˆ°5-10
4. ä½¿ç”¨æ›´å¤§çš„LoRA rank

### Q4: å¦‚ä½•ä¸Task1å¯¹æ¯”?

**A**:
```python
# Task 1 CNNç»“æœ
Task1_Acc = 0.94
Task1_F1 = 0.78
Task1_AUC = 0.96

# Task 2 LLMç»“æœ
Task2_Acc = ?
Task2_F1 = ?

# åˆ†æ:
# - å‡†ç¡®ç‡æå‡? â†’ LLMç†è§£èƒ½åŠ›
# - F1æå‡? â†’ å°‘æ•°ç±»è¯†åˆ«èƒ½åŠ›
# - ç”Ÿæˆè´¨é‡? â†’ å¯è§£é‡Šæ€§
```

### Q5: k_size_stream2å‚æ•°é”™è¯¯?

**A**: å¿…é¡»ä¸Task1è®­ç»ƒæ—¶ä¸€è‡´!

```bash
# æ£€æŸ¥Task1ä½¿ç”¨çš„kå€¼
grep "Stream 2 k_size" /home/zhenwei/workspace/ecg/task1/results/test_results_*.txt

# ä½¿ç”¨ç›¸åŒçš„kå€¼
python task2_train.py --k_size_stream2 5  # æˆ–7æˆ–9
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®å±‚é¢
- [ ] å°è¯•åœ¨Task2ä¹Ÿä½¿ç”¨æ•°æ®å¢å¼º
- [ ] è°ƒæ•´Aç±»æ ·æœ¬çš„è¿‡é‡‡æ ·ç­–ç•¥
- [ ] ä¼˜åŒ–æŒ‡ä»¤æ¨¡æ¿å’Œç­”æ¡ˆæ ¼å¼

### 2. æ¨¡å‹å±‚é¢
- [ ] å®éªŒä¸åŒçš„LoRA rank (8/16/32)
- [ ] å°è¯•æ›´æ·±çš„Projector (3å±‚MLP)
- [ ] ä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–

### 3. è®­ç»ƒå±‚é¢
- [ ] è°ƒæ•´å­¦ä¹ ç‡ (5e-5 / 2e-4)
- [ ] å¢åŠ è®­ç»ƒè½®æ•° (5-10 epochs)
- [ ] ä½¿ç”¨cosineå­¦ä¹ ç‡è°ƒåº¦

---

## å‚è€ƒèµ„æ–™

- **LoRAè®ºæ–‡**: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- **Qwenæ¨¡å‹**: [Qwen Technical Report](https://arxiv.org/abs/2309.16609)
- **PEFTåº“**: [Hugging Face PEFT](https://github.com/huggingface/peft)

---

## é¡¹ç›®çŠ¶æ€

- [x] æ•°æ®é›†å‡†å¤‡
- [x] æ¨¡å‹æ¶æ„è®¾è®¡
- [x] è®­ç»ƒè„šæœ¬å®ç°
- [x] åŸºç¡€è¯„ä¼°åŠŸèƒ½
- [ ] æ¨ç†è„šæœ¬ä¼˜åŒ–
- [ ] è¯¦ç»†æ€§èƒ½åˆ†æ
- [ ] å¯è§†åŒ–å·¥å…·

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜,è¯·æ£€æŸ¥:
1. Task1æ¨¡å‹æƒé‡è·¯å¾„æ˜¯å¦æ­£ç¡®
2. Qwenæ¨¡å‹æ˜¯å¦å®Œæ•´ä¸‹è½½
3. GPUæ˜¾å­˜æ˜¯å¦å……è¶³
4. ä¾èµ–ç‰ˆæœ¬æ˜¯å¦åŒ¹é…

**é¢„æœŸç›®æ ‡**: Task2åº”åœ¨Task1åŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡åˆ†ç±»æ€§èƒ½,åŒæ—¶æä¾›å¯è§£é‡Šçš„è¯Šæ–­æ–‡æœ¬ã€‚
